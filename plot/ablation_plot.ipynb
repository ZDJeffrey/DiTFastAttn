{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dit_fast_attention\n",
    "import os\n",
    "file_path=os.path.abspath(dit_fast_attention.__file__)\n",
    "dir_path=os.path.dirname(file_path)\n",
    "os.chdir(dir_path)\n",
    "from diffusers import DiTPipeline, DPMSolverMultistepScheduler\n",
    "import argparse\n",
    "import torch\n",
    "from evaluation import test_latencies\n",
    "from dit_fast_attention import transform_model_fast_attention\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import thop\n",
    "from utils import calculate_flops\n",
    "import re\n",
    "import seaborn as sns\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "from collections import namedtuple\n",
    "os.environ[\"https_proxy\"]=\"http://10.10.20.100:1089\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "def parse_txt_data(txt_data):\n",
    "    data = []\n",
    "    for block in txt_data.split('\\n\\n'):\n",
    "        lines = block.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            if line.startswith('Namespace'):\n",
    "                namespace = re.findall(r\"Namespace\\((.*)\\)\", line)[0]\n",
    "                namespace_args = [arg.split('=') for arg in namespace.split(', ')]\n",
    "                namespace_dict = {arg[0]: eval(arg[1]) for arg in namespace_args}\n",
    "                # namespace_obj = namedtuple('Namespace', namespace_dict.keys())(**namespace_dict)\n",
    "                data.append(namespace_dict)\n",
    "            # elif line.startswith('calib_ssim'):\n",
    "            #     calib_ssim = float(line.split('=')[1])\n",
    "            #     # data.append(calib_ssim)\n",
    "            #     namespace_dict[\"calib_ssim\"] = calib_ssim\n",
    "            elif line.startswith('{'):\n",
    "                metrics = eval(line)\n",
    "                # data.append(metrics)\n",
    "                namespace_dict[\"metrics\"] = metrics\n",
    "            elif line.startswith('macs'):\n",
    "                macs = eval(line.split('=')[1])\n",
    "                namespace_dict[\"macs\"] = macs\n",
    "                # data.append(macs)\n",
    "            elif line.startswith('attn_mac'):\n",
    "                attn_mac = float(line.split('=')[1])\n",
    "                # data.append(attn_mac)\n",
    "                namespace_dict[\"attn_mac\"] = attn_mac\n",
    "            elif line.startswith('latencies'):\n",
    "                latencies = eval(line.split('=')[1])\n",
    "                # data.append(latencies)\n",
    "                namespace_dict[\"latencies\"] = latencies\n",
    "                # print(latencies)\n",
    "    return data\n",
    "\n",
    "txt_data=open(\"output/results.txt\").read()\n",
    "data=parse_txt_data(txt_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation plot\n",
    "seqs=[1,0.975,0.95,0.925,0.9,0.875,0.85]\n",
    "seqs=[0.975,0.95,0.925,0.9,0.875,0.85]\n",
    "# sfig, saxes = plt.subplots(1,3,figsize=(3.8*3,1.5))\n",
    "fig=plt.figure(figsize=(6,2))\n",
    "ax=fig.add_subplot(121)\n",
    "# titles=[\"512x512 DiT-XL\",\"1024x1024 PixArt-Sigma-XL\",\"2048x2048 PixArt-Sigma-XL\"]\n",
    "\n",
    "raw_macs=2705/1e3\n",
    "raw_fid=30.868\n",
    "raw_is=210.0112\n",
    "for modeli, model_name in enumerate([\"facebook/DiT-XL-2-512\"]):\n",
    "    nbatch=8 if model_name==\"facebook/DiT-XL-2-512\" else 1\n",
    "    \n",
    "    for ablation in [\"\",\"full_attn+cfg_attn_share\",\"residual_window_attn\",\"output_share\"]:\n",
    "        # lats_all=[]\n",
    "        # lats_attn=[]\n",
    "        if ablation==\"output_share\":\n",
    "            seqs=seqs[1:]\n",
    "        iss=[raw_is]\n",
    "        attn_macs=[raw_macs]\n",
    "        visited=[]\n",
    "        for threshold in seqs:\n",
    "            for l in data[::-1]:\n",
    "                # print(l)\n",
    "                if l[\"model\"]==model_name and l[\"n_calib\"]==8 and l[\"n_steps\"]==20 and \\\n",
    "                    l[\"eval_n_images\"]==5000 and \"attn_mac\" in l and l[\"threshold\"]==threshold \\\n",
    "                        and l.get(\"ablation\",\"\")==ablation:\n",
    "                    # if \"metrics\" not in l or not \"IS\" in l[\"metrics\"]:\n",
    "                    #     continue\n",
    "                    if \"metrics\" not in l or not \"IS\" in l[\"metrics\"]:\n",
    "                        continue\n",
    "                    if l[\"threshold\"] in visited:\n",
    "                        continue\n",
    "                    visited.append(l[\"threshold\"])\n",
    "                    attn_macs.append(l[\"attn_mac\"]/1e3)\n",
    "                    iss.append(l[\"metrics\"][\"IS\"][0].item())\n",
    "                    # lats_all.append(l[\"latencies\"][f\"{nbatch}_all\"])\n",
    "                    # lats_attn.append(l[\"latencies\"][f\"{nbatch}_attn\"])\n",
    "        ablation=\"DiTFastAttn\" if ablation==\"\" else ablation\n",
    "        ablation=ablation.replace(\"full_attn+\",\"\").replace(\"cfg_attn_share\",\"ASC\").replace(\"residual_window_attn\",\"WA\").replace(\"output_share\",\"AST\")    \n",
    "        ax.plot(attn_macs, iss, label=f\"{ablation}\")\n",
    "        # ax.plot(attn_macs, lats_attn, label=\"Attention\")\n",
    "        # ax.set_title(titles[modeli])\n",
    "        ax.legend()\n",
    "        ax.set_ylabel(\"Inception Score\")\n",
    "        ax.set_xlabel(\"Attention TFLOPs\")\n",
    "        # print(f\"{model_name} IS\",iss)\n",
    "        # print(f\"{model_name} Attention\",attn_macs)\n",
    "        print(iss)\n",
    "        print(attn_macs)\n",
    "\n",
    "plt.ylim(190,211)\n",
    "plt.xlim(1.75,2.75)\n",
    "# sfig.show()\n",
    "# fig.savefig(\"plot/ablation.pdf\", bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = DiTPipeline.from_pretrained(\"facebook/DiT-XL-2-512\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "calib_x=torch.randint(0, 1000, (1,),generator=torch.Generator().manual_seed(3)).to(\"cuda\")\n",
    "n_stepss=[20,30,40,50,60]\n",
    "\n",
    "steps_macs=[]\n",
    "for n_steps in n_stepss:\n",
    "    _,a_macs=calculate_flops(pipe,calib_x,n_steps=n_steps)\n",
    "    steps_macs.append(a_macs/1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation plot\n",
    "seqs=[1,0.975,0.95,0.925,0.9,0.875,0.85]\n",
    "seqs=[0.975,0.95,0.925,0.9,0.875,0.85]\n",
    "# sfig, saxes = plt.subplots(1,3,figsize=(3.8*3,1.5))\n",
    "n_stepss=[20,30,40]\n",
    "ax=fig.add_subplot(122)\n",
    "# titles=[\"512x512 DiT-XL\",\"1024x1024 PixArt-Sigma-XL\",\"2048x2048 PixArt-Sigma-XL\"]\n",
    "\n",
    "for modeli, model_name in enumerate([\"facebook/DiT-XL-2-512\"]):\n",
    "    nbatch=8 if model_name==\"facebook/DiT-XL-2-512\" else 1\n",
    "    for n_steps in n_stepss:\n",
    "        iss=[]\n",
    "        attn_macs=[]\n",
    "        visited=[]\n",
    "        for threshold in seqs:\n",
    "            for l in data[::-1]:\n",
    "                # print(l)\n",
    "                if l[\"model\"]==model_name and l[\"n_calib\"]==8 and l[\"n_steps\"]==n_steps and \\\n",
    "                    l[\"eval_n_images\"]==5000 and \"attn_mac\" in l and l[\"threshold\"]==threshold and l.get(\"ablation\",\"\")==\"\":\n",
    "                    # if \"metrics\" not in l or not \"IS\" in l[\"metrics\"]:\n",
    "                    #     continue\n",
    "                    if \"metrics\" not in l or not \"IS\" in l[\"metrics\"]:\n",
    "                        continue\n",
    "                    if l[\"threshold\"] in visited:\n",
    "                        continue\n",
    "                    visited.append(l[\"threshold\"])\n",
    "                    attn_macs.append(l[\"attn_mac\"]/1e3)\n",
    "                    iss.append(l[\"metrics\"][\"IS\"][0].item())\n",
    "                    # lats_all.append(l[\"latencies\"][f\"{nbatch}_all\"])\n",
    "                    # lats_attn.append(l[\"latencies\"][f\"{nbatch}_attn\"])\n",
    "        raw_macs=steps_macs[n_stepss.index(n_steps)]\n",
    "        if len(iss)==0:\n",
    "            continue\n",
    "        raw_is=iss[0]\n",
    "        iss=[raw_is]+iss\n",
    "        attn_macs=[raw_macs]+attn_macs\n",
    "        attn_macs=np.array(attn_macs)/raw_macs\n",
    "        ax.plot(attn_macs, iss, label=f\"steps={n_steps}\")\n",
    "        # ax.plot(attn_macs, lats_attn, label=\"Attention\")\n",
    "        # ax.set_title(titles[modeli])\n",
    "        ax.legend()\n",
    "        ax.set_ylabel(\"Inception Score\")\n",
    "        ax.set_xlabel(\"Attention TFLOPs Fraction\")\n",
    "        # print(f\"{model_name} IS\",iss)\n",
    "        # print(f\"{model_name} Attention\",attn_macs)\n",
    "        print(iss)\n",
    "        print(attn_macs)\n",
    "fig.tight_layout()\n",
    "# plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=2, hspace=2)\n",
    "\n",
    "# plt.ylim(190,211)\n",
    "# plt.xlim(1.75,2.75)\n",
    "# sfig.show()\n",
    "fig.savefig(\"plot/ablation.jpg\", bbox_inches='tight')\n",
    "fig.savefig(\"plot/ablation.pdf\", bbox_inches='tight')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dit_fa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
